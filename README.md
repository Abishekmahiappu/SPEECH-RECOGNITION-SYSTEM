# SPEECH-RECOGNITION-SYSTEM

*COMPANY*:CODTECH IT SOLUTIONS

*NAME*:ABISHEK B

*INTERN ID*: CT04DH2896

*DOMAIN*: ARTIFICIAL INTELLIGENCE

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTHOSH

*DESCRIPTION*:  I started working on this Speech Recognition System project with the core idea of converting human speech into readable text. My goal was to build a functional and lightweight speech-to-text converter that can work efficiently for short voice commands or dictation-like input. I began by analyzing the basic concept of speech recognition, understanding how human voice gets processed, and how models and libraries can help transcribe audio into text format. To kickstart my research, I first referred to the book "Speech and Language Processing" by Jurafsky and Martin, which gave me a theoretical understanding of phonetics, speech features, acoustic modeling, and language modeling. Then, I shifted my focus toward more hands-on learning through a combination of experimentation and online resources. I explored the Python speech_recognition library, which is simple and well-documented for beginner-friendly projects. I implemented a basic microphone-to-text conversion setup using this library. This version of the system was quick and effective, but I soon realized it had limitations in terms of accuracy and required an active internet connection as it depends on Google’s API. To enhance the accuracy and make the system work offline as well, I decided to explore pre-trained deep learning models, particularly Facebook AI’s Wav2Vec2.0, which is hosted on the Hugging Face Transformers platform. I studied the Wav2Vec architecture, how it leverages self-supervised learning, and how it performs well with less training data. I followed a few in-depth YouTube tutorials from creators like Codebasics, Krish Naik, and The AI Guy, who demonstrated how to implement Wav2Vec in Python. Their videos provided a step-by-step understanding of how to tokenize audio, run inference using the model, and decode results into human-readable text. I also learned how to preprocess audio files using librosa, a powerful library for audio analysis. I experimented with audio sampling rates and trimming silences to get the cleanest input. After setting up the deep learning model, I developed a working Python script that can transcribe audio clips with great accuracy. To make the project more interactive, I also built a browser-based version using HTML, CSS, and JavaScript, leveraging the Web Speech API available in modern browsers.
